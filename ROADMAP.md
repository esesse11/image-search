# ğŸ—ºï¸ Development Roadmap

**í”„ë¡œì íŠ¸ëª…**: Image Search System
**íƒ€ì„ë¼ì¸**: 3ì£¼ (Phase 1~3)
**ì˜ˆì‚°**: ~$50-100 (OpenAI API, í”„ë¦¬í‹°ì–´ VM í™œìš©)
**ë°°í¬ íƒ€ê²Ÿ**: WSL2 ë¡œì»¬ â†’ AWS Lightsail / Oracle Free Tier

---

## ğŸ“… Timeline Overview

```
Week 1: Foundation (ê¸°ì´ˆ êµ¬ì¶•)
â”œâ”€ Day 1-2: Project Initialization âœ… (ì™„ë£Œ)
â”œâ”€ Day 3-4: Core Modules (API, Ingest, Index)
â””â”€ Day 5: Testing & Debugging

Week 2: Feature Development (ê¸°ëŠ¥ ê°œë°œ)
â”œâ”€ Day 6-7: Ingest Pipeline (Captioning, Attributes)
â”œâ”€ Day 8-9: Search API (FAISS Integration)
â””â”€ Day 10: Performance Optimization

Week 3: Polish & Deployment (ì™„ì„± & ë°°í¬)
â”œâ”€ Day 11-12: Streamlit UI
â”œâ”€ Day 13: Fine-tuning Setup (Optional)
â”œâ”€ Day 14: Local Testing
â””â”€ Day 15: Production Deployment

```

---

## Phase 1: Foundation (Days 1-5) - ì§„í–‰ ì¤‘ âœ…

### âœ… Day 1-2: Project Initialization (ì™„ë£Œ)

**ì‚°ì¶œë¬¼:**
- [x] í´ë” êµ¬ì¡° ìƒì„±
- [x] config.yaml ì‘ì„± (ëª¨ë“  ì„¤ì • í†µí•©)
- [x] requirements.txt (ëª¨ë“  ì˜ì¡´ì„±)
- [x] .env.example (í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿)
- [x] .gitignore (Git ì œì™¸ íŒŒì¼)
- [x] README.md (ì„¤ì¹˜/ì‚¬ìš© ê°€ì´ë“œ)
- [x] ARCHITECTURE.md (ìƒì„¸ ì•„í‚¤í…ì²˜)
- [x] ROADMAP.md (ì´ íŒŒì¼)

**ë‹¤ìŒ ì²´í¬:**
```bash
cd image-search
ls -la
# config.yaml, requirements.txt, .env.example, README.md âœ“
```

---

### ğŸ”¨ Day 3-4: Core Modules (ì˜ˆì •)

#### Task 1: FastAPI ê¸°ë³¸ êµ¬ì¡°

**íŒŒì¼:**
- `app/api/main.py` - FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
- `app/api/search.py` - ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸
- `app/api/assets.py` - ì´ë¯¸ì§€ ë©”íƒ€ ì—”ë“œí¬ì¸íŠ¸
- `app/api/feedback.py` - í”¼ë“œë°± ìˆ˜ì§‘

**êµ¬í˜„:**
```python
# app/api/main.py
from fastapi import FastAPI
from app.api import search, assets, feedback

app = FastAPI(title="Image Search API")
app.include_router(search.router)
app.include_router(assets.router)
app.include_router(feedback.router)

@app.get("/health")
async def health():
    return {"status": "ok"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**í…ŒìŠ¤íŠ¸:**
```bash
uvicorn app.api.main:app --reload
# ë¸Œë¼ìš°ì €: http://localhost:8000/docs
```

#### Task 2: Database ì„¤ì •

**íŒŒì¼:**
- `app/common/database.py` - SQLAlchemy ì„¤ì •
- `app/common/models.py` - ORM ëª¨ë¸

**êµ¬í˜„:**
```python
# app/common/models.py
from sqlalchemy import Column, String, JSON, DateTime
from datetime import datetime

class Image(Base):
    __tablename__ = "images"

    id = Column(String, primary_key=True)
    caption = Column(String)
    attributes = Column(JSON)  # {"color": ["blue"], ...}
    palette = Column(JSON)     # ["#4A90E2", "#FFFFFF"]
    embedding = Column(JSON)   # [0.1, -0.2, ...]
    created_at = Column(DateTime, default=datetime.utcnow)

class Feedback(Base):
    __tablename__ = "feedback"

    id = Column(Integer, primary_key=True)
    query = Column(String)
    image_id = Column(String)
    relevance = Column(Integer)  # 0 or 1
```

#### Task 3: Config Loader

**íŒŒì¼:**
- `app/common/config.py` - ì„¤ì • ë¡œë”

**êµ¬í˜„:**
```python
# app/common/config.py
from pydantic import BaseSettings
import yaml

class Settings(BaseSettings):
    api_host: str = "0.0.0.0"
    api_port: int = 8000
    db_path: str = "./app/data/images.db"
    ...

    class Config:
        env_file = ".env"

def load_config(path: str = "config.yaml"):
    with open(path) as f:
        yaml_config = yaml.safe_load(f)
    return yaml_config
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸:**
```
- [ ] app/api/main.py ì‘ì„± ë° í…ŒìŠ¤íŠ¸
- [ ] app/common/models.py ì‘ì„±
- [ ] app/common/database.py ì‘ì„±
- [ ] app/common/config.py ì‘ì„±
- [ ] FastAPI /health ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
- [ ] SQLite í…Œì´ë¸” ìƒì„± í…ŒìŠ¤íŠ¸
```

---

### ğŸ§ª Day 5: Testing & Debugging

**í…ŒìŠ¤íŠ¸ í•­ëª©:**
```bash
# 1. API ì •ìƒ ì‘ë™
curl http://localhost:8000/health
# {"status": "ok"}

# 2. DB ì—°ê²°
python -c "from app.common.database import SessionLocal; db = SessionLocal(); print('âœ“ DB OK')"

# 3. ì„¤ì • ë¡œë“œ
python -c "from app.common.config import load_config; c = load_config(); print(c['api'])"

# 4. .env íŒŒì¼ í™•ì¸
cat .env  # OPENAI_API_KEY ì„¤ì • í™•ì¸

# 5. ëª¨ë¸ ê²€ì¦
python -c "from app.common.models import ImageAttributes; a = ImageAttributes(color=['blue']); print(a)"
```

**ì‚°ì¶œë¬¼:**
- âœ… FastAPI ê¸°ë³¸ êµ¬ì¡° ì™„ì„±
- âœ… SQLite DB ì´ˆê¸°í™” + 7ê°œ ì†ì„± ëª¨ë¸
- âœ… ì„¤ì • ì‹œìŠ¤í…œ í†µí•©
- âœ… Git ì»¤ë°‹ & í‘¸ì‹œ

---

## Phase 2: Feature Development (Days 6-10) - ì˜ˆì •

### ğŸ–¼ï¸ Day 6-7: Ingest Pipeline

#### Task 1: Image Preprocessing

**íŒŒì¼:** `app/ingest/preprocessor.py`

```python
class Preprocessor:
    def process_image(self, image_path: str):
        # 1. ì´ë¯¸ì§€ ë¡œë“œ (PIL)
        img = Image.open(image_path)

        # 2. ë¦¬ì‚¬ì´ì§• (512x512)
        img.thumbnail((512, 512))

        # 3. ì •ê·œí™”
        # (0-255) â†’ (0-1)

        # 4. ì¸ë„¤ì¼ ìƒì„± (256x256)

        return processed_img
```

**í…ŒìŠ¤íŠ¸:**
```bash
python -m app.ingest.preprocessor --test
```

#### Task 2: Image Captioning

**íŒŒì¼:** `app/ingest/captioner.py`

```python
from openai import OpenAI

class Captioner:
    def generate(self, image_path: str):
        # OpenAI Vision API í˜¸ì¶œ
        # ì…ë ¥: ì´ë¯¸ì§€
        # ì¶œë ¥: "íŒŒë€ìƒ‰ ë©´ ë“œë ˆìŠ¤, ì—¬ë¦„ ì‹œì¦Œ"

        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-4-vision",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": image_url}},
                        {"type": "text", "text": "Describe this clothing item in Korean..."}
                    ]
                }
            ]
        )
        return response.choices[0].message.content
```

**ì˜ˆìƒ ë¹„ìš©:** 100ê°œ ì´ë¯¸ì§€ Ã— $0.03/image = $3

#### Task 3: Attribute Extraction

**íŒŒì¼:** `app/ingest/extractor.py`

```python
class Extractor:
    def extract(self, caption: str, image_path: str):
        # ìº¡ì…˜ì—ì„œ structured attributes ì¶”ì¶œ
        # ì˜ˆ: "íŒŒë€ìƒ‰ ë©´ ë“œë ˆìŠ¤" â†’ {
        #   "color": ["blue"],
        #   "material": ["cotton"],
        #   "style": ["dress"]
        # }

        # ë°©ë²• 1: LLM (ë” ì •í™•)
        # ë°©ë²• 2: ê·œì¹™ ê¸°ë°˜ (ë¹ ë¦„)
```

#### Task 4: Color Palette

**íŒŒì¼:** `app/ingest/palette.py`

```python
class PaletteExtractor:
    def extract_palette(self, image_path: str, num_colors: int = 5):
        # K-means clusteringìœ¼ë¡œ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ
        # PIL + scikit-learn ì‚¬ìš©

        from sklearn.cluster import KMeans
        import colorsys

        colors = KMeans(n_clusters=num_colors).fit(pixels)
        hex_colors = [self._rgb_to_hex(c) for c in colors.cluster_centers_]
        return hex_colors
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸:**
```
- [ ] app/ingest/preprocessor.py ì‘ì„±
- [ ] app/ingest/captioner.py ì‘ì„± (OpenAI Vision)
- [ ] app/ingest/extractor.py ì‘ì„±
- [ ] app/ingest/palette.py ì‘ì„±
- [ ] í†µí•© pipeline.py ì‘ì„±
- [ ] ìƒ˜í”Œ 10ê°œ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
```

---

### ğŸ” Day 8-9: Search API & Indexing

#### Task 1: Embedder

**íŒŒì¼:** `app/index/embedder.py`

```python
from openai import OpenAI

class Embedder:
    def embed(self, text: str):
        # OpenAI text-embedding-3-small
        # ì…ë ¥: "íŒŒë€ìƒ‰ ì—¬ë¦„ ë“œë ˆìŠ¤"
        # ì¶œë ¥: [0.1, -0.2, ..., 0.8] (1536 dims)

        client = OpenAI()
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding

    def embed_batch(self, texts: List[str]):
        # ë°°ì¹˜ ì²˜ë¦¬ (ë” íš¨ìœ¨ì )
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=texts
        )
        return [item.embedding for item in response.data]
```

**ì˜ˆìƒ ë¹„ìš©:** 1,000ê°œ ì´ë¯¸ì§€ ì¸ë±ì‹± = ~1M tokens â‰ˆ $0.02

#### Task 2: FAISS Index

**íŒŒì¼:** `app/index/faiss_index.py`

```python
import faiss
import numpy as np

class FAISSIndex:
    def __init__(self, dim=1536):
        self.index = faiss.IndexFlatIP(dim)  # Inner Product
        self.id_map = {}

    def add(self, vectors: np.ndarray, ids: List[str]):
        # ë²¡í„° ì¶”ê°€
        self.index.add(vectors)
        self.id_map = {i: id for i, id in enumerate(ids)}

    def search(self, query_vector: np.ndarray, k: int = 20):
        # ê²€ìƒ‰
        scores, indices = self.index.search(
            query_vector.reshape(1, -1), k
        )
        return [(self.id_map[i], s) for i, s in zip(indices[0], scores[0])]

    def save(self, path: str):
        faiss.write_index(self.index, path)

    def load(self, path: str):
        self.index = faiss.read_index(path)
```

#### Task 3: Build Script

**íŒŒì¼:** `app/index/build.py`

```bash
python -m app.index.build \
  --input ./app/data/raw_images \
  --use faiss \
  --batch-size 100
```

#### Task 4: Search Endpoint

**íŒŒì¼:** `app/api/search.py` (ì—…ë°ì´íŠ¸)

```python
@router.post("/search/text")
async def search_text(query: SearchQuery):
    # 1. ì¿¼ë¦¬ ë²¡í„°í™”
    query_vector = embedder.embed(query.query)

    # 2. FAISS ê²€ìƒ‰
    scores, image_ids = index.search(query_vector, k=40)

    # 3. ë©”íƒ€ ë¡œë“œ
    images = db.get_images(image_ids)

    # 4. ìŠ¤ì½”ì–´ë§
    results = []
    for img in images:
        score = calculate_score(img, query.w_caption, query.w_attrs)
        results.append({
            "id": img.id,
            "score": score,
            "caption": img.caption,
            "attributes": img.attributes
        })

    # 5. ì •ë ¬ ë° í•„í„°ë§
    results = sorted(results, key=lambda x: x["score"], reverse=True)
    return {"results": results[:20]}
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸:**
```
- [ ] app/index/embedder.py ì‘ì„±
- [ ] app/index/faiss_index.py ì‘ì„±
- [ ] app/index/build.py ì‘ì„±
- [ ] app/api/search.py êµ¬í˜„
- [ ] ê²€ìƒ‰ API í…ŒìŠ¤íŠ¸
  curl -X POST http://localhost:8000/search/text \
    -H "Content-Type: application/json" \
    -d '{"query": "íŒŒë€ìƒ‰ ë“œë ˆìŠ¤", "top_k": 10}'
```

---

### âš¡ Day 10: Performance Optimization

**ìµœì í™” í•­ëª©:**

1. **ì„ë² ë”© ìºì‹±**
   ```python
   # ì´ë¯¸ ê³„ì‚°í•œ ë²¡í„°ëŠ” ìºì‹œì—ì„œ ë¡œë“œ
   cache = JSONCache("./app/data/embeddings_cache")
   ```

2. **ë°°ì¹˜ ì²˜ë¦¬**
   ```python
   # 100ê°œì”© ë¬¶ì–´ì„œ API í˜¸ì¶œ
   for batch in chunks(images, 100):
       embeddings = embedder.embed_batch(batch)
   ```

3. **ì¸ë±ìŠ¤ ìµœì í™”**
   ```python
   # GPU ì‚¬ìš© (ìˆìœ¼ë©´)
   index = faiss.index_cpu_to_gpu(gpu_resource, 0, index)
   ```

4. **DB ì¸ë±ì‹±**
   ```sql
   CREATE INDEX idx_attributes ON images(attributes);
   ```

---

## Phase 3: Polish & Deployment (Days 11-15) - ì˜ˆì •

### ğŸ¨ Day 11-12: Streamlit UI

**íŒŒì¼ êµ¬ì¡°:**
```
app/ui/
â”œâ”€â”€ app.py              # ë©”ì¸ í˜ì´ì§€
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ detail.py       # ìƒì„¸ë³´ê¸°
â”‚   â””â”€â”€ history.py      # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬
â””â”€â”€ components/
    â”œâ”€â”€ search_bar.py
    â”œâ”€â”€ filters.py
    â””â”€â”€ result_cards.py
```

**ê¸°ë³¸ êµ¬í˜„:**
```python
# app/ui/app.py
import streamlit as st
from app.ui.components import SearchBar, ResultCards

st.set_page_config(page_title="Image Search", layout="wide")

# 1. ê²€ìƒ‰ ì…ë ¥
query = st.text_input("ğŸ” ê²€ìƒ‰", placeholder="íŒŒë€ìƒ‰ ì—¬ë¦„ ë“œë ˆìŠ¤")

# 2. í•„í„°
col1, col2, col3 = st.columns(3)
color_filter = col1.multiselect("ìƒ‰ìƒ", ["ë¹¨ê°•", "íŒŒë‘", "ê²€ì •"])
season_filter = col2.multiselect("ì‹œì¦Œ", ["ë´„", "ì—¬ë¦„", "ê°€ì„", "ê²¨ìš¸"])

# 3. ê²€ìƒ‰ ì‹¤í–‰
if query:
    results = api_client.search(
        query=query,
        filters={
            "color": color_filter,
            "season": season_filter
        }
    )

    # 4. ê²°ê³¼ í‘œì‹œ
    ResultCards(results).display()
```

**ì‹¤í–‰:**
```bash
streamlit run app/ui/app.py
```

### ğŸ§‘â€ğŸ« Day 13: Fine-tuning Setup â­ (í•„ìˆ˜ - ì„ íƒë¨)

**ëª©ì :**
- ì‚¬ë‚´ í‘œì¤€ ìº¡ì…˜ í¬ë§· í•™ìŠµ (SFT)
- ê²€ìƒ‰ ì¬ì •ë ¬ ì„ í˜¸ë„ í•™ìŠµ (DPO)

**íŒŒì¼:**
```
training/
â”œâ”€â”€ make_jsonl.py      # DB/í”¼ë“œë°± â†’ JSONL ë³€í™˜
â”œâ”€â”€ finetune.py        # OpenAI Fine-tuning API ì‹¤í–‰
â”œâ”€â”€ evaluate.py        # íŒŒì¸íŠœë‹ ëª¨ë¸ í‰ê°€
â”œâ”€â”€ sft_data.jsonl     # SFT í•™ìŠµ ë°ì´í„°
â””â”€â”€ dpo_data.jsonl     # DPO í•™ìŠµ ë°ì´í„°
```

**SFT (Supervised Fine-Tuning):**
```python
# training/make_jsonl.py - SFT ë°ì´í„° ìƒì„±
from app.common.database import SessionLocal
from app.common.models import Image

db = SessionLocal()
sft_data = []

for image in db.query(Image).all():
    sft_data.append({
        "messages": [
            {"role": "user", "content": image.caption},
            {"role": "assistant", "content": f"Color: {image.attributes['color']} | Material: {image.attributes['material']} | Style: {image.attributes['style']}"}
        ]
    })

# 500+ ìƒ˜í”Œ ìƒì„± ë° sft_data.jsonlë¡œ ì €ì¥
```

**DPO (Direct Preference Optimization):**
```python
# ê²€ìƒ‰ í”¼ë“œë°±ìœ¼ë¡œ ì„ í˜¸ë„ ë°ì´í„° ìƒì„±
# feedback í…Œì´ë¸”ì—ì„œ relevance=1 (ì¢‹ìŒ) vs relevance=0 (ë‚˜ì¨)
# â†’ dpo_data.jsonl ìƒì„±
```

**íŒŒì¸íŠœë‹ ì‹¤í–‰:**
```bash
python training/finetune.py \
  --model gpt-3.5-turbo \
  --training-file sft_data.jsonl \
  --validation-file dpo_data.jsonl \
  --epochs 3

# ë¹„ìš©: ~$10-20 (SFT + DPO)
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸:**
```
- [ ] training/make_jsonl.py ì‘ì„±
- [ ] training/finetune.py ì‘ì„±
- [ ] training/evaluate.py ì‘ì„±
- [ ] SFT ë°ì´í„° ìƒì„± (500+ ìƒ˜í”Œ)
- [ ] DPO ë°ì´í„° ìƒì„± (100+ ìŒ)
- [ ] íŒŒì¸íŠœë‹ ì‹¤í–‰
- [ ] ì„±ëŠ¥ ë¹„êµ (ê¸°ë³¸ vs íŒŒì¸íŠœë‹)
```

### âœ… Day 14: Local Testing

**í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸:**
```
- [ ] API ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
  - POST /search/text
  - GET /asset/{id}
  - POST /feedback

- [ ] UI ëª¨ë“  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
  - ê²€ìƒ‰ ì…ë ¥
  - í•„í„° ì ìš©
  - ê²°ê³¼ í‘œì‹œ

- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
  - ê²€ìƒ‰ ì‘ë‹µ ì‹œê°„ < 100ms
  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ < 2GB

- [ ] ì—ëŸ¬ ì²˜ë¦¬
  - ì—†ëŠ” ì¿¼ë¦¬
  - API ì—ëŸ¬
  - DB ì—ëŸ¬
```

### ğŸš€ Day 15: Production Deployment

**ë°°í¬ ì˜µì…˜:**

#### ì˜µì…˜ 1: AWS Lightsail (ê¶Œì¥)
```bash
# 1. VM ìƒì„± (Ubuntu 22.04, 1GB RAM, $4/ì›”)
# 2. SSH ì ‘ì†
ssh -i key.pem ubuntu@ip

# 3. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/esesse11/image-search.git
cd image-search

# 4. í™˜ê²½ ì„¤ì •
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# 5. .env ì„¤ì •
echo "OPENAI_API_KEY=sk-..." > .env

# 6. systemd ì„œë¹„ìŠ¤ ë“±ë¡
sudo cp deployment/image-search-api.service /etc/systemd/system/
sudo systemctl enable image-search-api
sudo systemctl start image-search-api

# 7. Nginx ì„¤ì • (ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ)
sudo cp deployment/nginx.conf /etc/nginx/sites-available/
sudo systemctl restart nginx

# 8. ëª¨ë‹ˆí„°ë§
curl http://localhost:8000/health
```

#### ì˜µì…˜ 2: Oracle Cloud Free Tier
```bash
# ë¹„ìŠ·í•œ ì ˆì°¨
# ë¬´ë£Œ 2ê°œ OCPU, 12GB RAM VM ì œê³µ
```

#### ì˜µì…˜ 3: ë¡œì»¬ WSL2 (ê°œë°œìš©)
```bash
# ê·¸ëƒ¥ ê³„ì† ì‚¬ìš©
uvicorn app.api.main:app --host 0.0.0.0
streamlit run app/ui/app.py
```

**ìµœì¢… ì‚°ì¶œë¬¼:**
- âœ… ëª¨ë“  ì†ŒìŠ¤ ì½”ë“œ
- âœ… ë°°í¬ ê°€ì´ë“œ (DEPLOYMENT.md)
- âœ… API ë¬¸ì„œ (Swagger /docs)
- âœ… ì‚¬ìš©ì ê°€ì´ë“œ (README.md)
- âœ… ê°œë°œì ê°€ì´ë“œ (ARCHITECTURE.md)

---

## ğŸ“Š Success Criteria

| í•­ëª© | ëª©í‘œ | ë‹¬ì„± ì—¬ë¶€ |
|------|------|---------|
| ê²€ìƒ‰ ì‘ë‹µ ì‹œê°„ | < 100ms | â“ |
| ê²€ìƒ‰ ì •í™•ë„ | > 0.8 (MRR) | â“ |
| API ì•ˆì •ì„± | 99.9% ê°€ìš©ì„± | â“ |
| ë©”ëª¨ë¦¬ ì‚¬ìš© | < 2GB | â“ |
| ë°°í¬ ë¹„ìš© | < $50/ì›” | â“ |
| ì½”ë“œ ì»¤ë²„ë¦¬ì§€ | > 80% | â“ |

---

## ğŸ”„ Feedback Loop

1. **ì£¼ê°„ ë¦¬ë·° (ë§¤ì£¼ ê¸ˆìš”ì¼)**
   - ì™„ë£Œëœ ì‘ì—… í™•ì¸
   - ì´ìŠˆ ë° ë¸”ë¡œì»¤ íŒŒì•…
   - ë‹¤ìŒì£¼ ê³„íš ì¡°ì •

2. **ì‚¬ìš©ì í”¼ë“œë°±**
   - /feedback ì—”ë“œí¬ì¸íŠ¸ë¡œ ê²€ìƒ‰ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
   - ê°œì„ ì•ˆ ì ìš©

3. **ì„±ëŠ¥ ë©”íŠ¸ë¦­**
   - API ì‘ë‹µ ì‹œê°„
   - ê²€ìƒ‰ ì •í™•ë„ (MRR, NDCG)
   - ì‚¬ìš©ì í”¼ë“œë°± ì •í™•ë„

---

## ğŸ“ Notes

- **ë¶ˆí™•ì‹¤í•œ í•­ëª©ë“¤ì€ ì§„í–‰í•˜ë©° ê²°ì •**
  - ìº¡ì…”ë‹: OpenAI Vision vs BLIP (ë¹„ìš©/ì„±ëŠ¥ íŠ¸ë ˆì´ë“œ)
  - ì†ì„± ì¶”ì¶œ: LLM vs ê·œì¹™ ê¸°ë°˜ (ì •í™•ë„/ì†ë„)
  - ì¸ë±ìŠ¤: FAISS vs Qdrant (ë‹¨ìˆœì„±/í™•ì¥ì„±)

- **ì´ˆê¸° ìš°ì„ ìˆœìœ„**
  1. ê¸°ë³¸ ê²€ìƒ‰ ê¸°ëŠ¥ (ì¿¼ë¦¬ â†’ ê²°ê³¼)
  2. UI ì™„ì„±
  3. ë°°í¬
  4. ì„±ëŠ¥ ìµœì í™” (ë‚˜ì¤‘)
  5. íŒŒì¸íŠœë‹ (ì„ íƒì‚¬í•­)

---

**ì‹œì‘ ì¼ì:** TBD
**ì˜ˆìƒ ì™„ë£Œì¼:** 3ì£¼ í›„
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:** 2025-11-08

